{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5CE1Mu8gYyEHNm1gL8hYs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0uLPr0X3XkW","executionInfo":{"status":"ok","timestamp":1725090214139,"user_tz":-345,"elapsed":26028,"user":{"displayName":"prizess_bs","userId":"05834432123457450151"}},"outputId":"2de5c151-f23f-4dce-92dd-07f3f4bd9a7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/mydrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/mydrive')\n","import os\n","#!pip install openpyxl\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","file = \"/content/mydrive/My Drive/Python/Clz/AI/LABWORKS/nb2.xlsx\"\n","df = pd.read_excel(file,index_col=0)\n","print(df)\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoders = {}\n","for column in ['Sector', 'Industry']:\n","    le = LabelEncoder()\n","    df[column] = le.fit_transform(df[column])\n","    label_encoders[column] = le\n","\n","print(df)\n","X, y=df.drop([\"Close\"],axis=1),df[\"Close\"]\n","print(X)\n","print(y)\n","import numpy as np\n","import pandas as pd\n","\n","class NaiveBayes:\n","    def __init__(self):\n","        self.features = None\n","        self.likelihoods = {}\n","        self.class_priors = {}\n","        self.pred_priors = {}\n","        self.X_train = None\n","        self.y_train = None\n","        self.train_size = 0\n","        self.num_feats = 0\n","\n","    def fit(self, X, y):\n","        self.features = list(X.columns)\n","        self.X_train = X\n","        self.y_train = y\n","        self.train_size = X.shape[0]\n","        self.num_feats = X.shape[1]\n","\n","        for feature in self.features:\n","            self.likelihoods[feature] = {}\n","            self.pred_priors[feature] = {}\n","            for feat_val in np.unique(self.X_train[feature]):\n","                self.pred_priors[feature][feat_val] = 0\n","                for outcome in np.unique(self.y_train):\n","                    self.likelihoods[feature][f'{feat_val}_{outcome}'] = 0\n","                    self.class_priors[outcome] = 0\n","\n","        self._calc_class_prior()\n","        self._calc_likelihoods()\n","        self._calc_predictor_prior()\n","\n","    def _calc_class_prior(self):\n","        for outcome in np.unique(self.y_train):\n","            outcome_count = sum(self.y_train == outcome)\n","            self.class_priors[outcome] = outcome_count / self.train_size\n","\n","    def _calc_likelihoods(self):\n","        for feature in self.features:\n","            for outcome in np.unique(self.y_train):\n","                outcome_count = sum(self.y_train == outcome)\n","                feat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n","                for feat_val, count in feat_likelihood.items():\n","                    self.likelihoods[feature][f'{feat_val}_{outcome}'] = (count + 1) / (outcome_count + len(feat_likelihood))  # Laplace smoothing\n","\n","    def _calc_predictor_prior(self):\n","        for feature in self.features:\n","            feat_val_counts = self.X_train[feature].value_counts().to_dict()\n","            for feat_val, count in feat_val_counts.items():\n","                self.pred_priors[feature][feat_val] = count / self.train_size\n","\n","    def predict(self, X):\n","        results = []\n","        X = np.array(X)\n","\n","        for query in X:\n","            probs_outcome = {}\n","            for outcome in np.unique(self.y_train):\n","                prior = self.class_priors[outcome]\n","                likelihood = 1\n","\n","                for feat, feat_val in zip(self.features, query):\n","                    if f'{feat_val}_{outcome}' in self.likelihoods[feat]:\n","                        likelihood *= self.likelihoods[feat][f'{feat_val}_{outcome}']\n","                    else:\n","                        likelihood *= 1 / (self.train_size + len(self.features))  # Adjust for unseen feature values\n","\n","                posterior = likelihood * prior\n","                probs_outcome[outcome] = posterior\n","\n","            result = max(probs_outcome, key=lambda x: probs_outcome[x])\n","            results.append(result)\n","\n","        return np.array(results)\n","\n","def accuracy_score(y_true, y_pred):\n","    return round(float(sum(y_pred == y_true)) / float(len(y_true)) * 100, 2)\n","\n","\n","\n","# Example usage\n","nb_clf = NaiveBayes()\n","nb_clf.fit(X, y)\n","\n","print(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n","# Query\n","query = np.array([[110, 115, 105, 180, 5300, 2, 2]])\n","print(\"Query:- {} ---> {}\".format(query, nb_clf.predict(query)))\n","\n"]}]}